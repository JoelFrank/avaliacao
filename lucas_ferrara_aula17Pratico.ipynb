{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random"
      ],
      "metadata": {
        "id": "gs6nQC70-ZvY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCnaYS3rUXrX",
        "outputId": "ae502593-8902-4025-c51e-dec8daa7edde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episódio 50: recompensa total = 0\n",
            "Episódio 100: recompensa total = -118\n",
            "Episódio 150: recompensa total = 0\n",
            "Episódio 200: recompensa total = 0\n",
            "Episódio 250: recompensa total = 0\n",
            "Episódio 300: recompensa total = 0\n",
            "\n",
            "Treinamento finalizado!\n",
            "\n",
            "Trajetória greedy:\n",
            "Posição: (1,1), Ouro: 0, Wumpus vivo: 1\n",
            "Fim do episódio.\n"
          ]
        }
      ],
      "source": [
        "# foi utitlizado chat gpt como auxilio para entender o codigo e a implementação em si\n",
        "\n",
        "# Ambiente do Mundo de Wumpus\n",
        "TAMANHO = 4\n",
        "CAVERNA = [\n",
        "    [' ', ' ', ' ', ' '],\n",
        "    ['W', ' ', 'A', ' '],\n",
        "    [' ', ' ', 'O', 'A'],\n",
        "    [' ', 'A', ' ', ' ']\n",
        "]\n",
        "\n",
        "# Recompensas\n",
        "RECOMPENSAS = {\n",
        "    'ouro': 100,\n",
        "    'abismo': -100,\n",
        "    'wumpus': -100,\n",
        "    'andar': -1,\n",
        "    'escalar_com_ouro': 50,\n",
        "    'atirar': -10\n",
        "}\n",
        "\n",
        "ACTIONS = ['norte', 'sul', 'leste', 'oeste', 'pegar', 'atirar', 'escalar']\n",
        "\n",
        "# Função para resetar o ambiente\n",
        "def reset_env():\n",
        "    return 0, 0, 1, 0, 1  # x, y, tem_flecha, tem_ouro, wumpus_vivo\n",
        "\n",
        "# Função para executar uma ação\n",
        "# Retorna novo estado, recompensa, done\n",
        "\n",
        "def step(state, action):\n",
        "    x, y, tem_flecha, tem_ouro, wumpus_vivo = state\n",
        "    reward = RECOMPENSAS['andar']\n",
        "    done = False\n",
        "    caverna = [row[:] for row in CAVERNA]\n",
        "\n",
        "    if action == 0:  # norte\n",
        "        if x > 0:\n",
        "            x -= 1\n",
        "    elif action == 1:  # sul\n",
        "        if x < TAMANHO-1:\n",
        "            x += 1\n",
        "    elif action == 2:  # leste\n",
        "        if y < TAMANHO-1:\n",
        "            y += 1\n",
        "    elif action == 3:  # oeste\n",
        "        if y > 0:\n",
        "            y -= 1\n",
        "    elif action == 4:  # pegar\n",
        "        if caverna[x][y] == 'O':\n",
        "            tem_ouro = 1\n",
        "            reward = RECOMPENSAS['ouro']\n",
        "            caverna[x][y] = ' '\n",
        "    elif action == 5:  # atirar\n",
        "        if tem_flecha:\n",
        "            tem_flecha = 0\n",
        "            reward = RECOMPENSAS['atirar']\n",
        "            # Simples: se Wumpus está na linha ou coluna, mata\n",
        "            if wumpus_vivo and (x == 1 and y <= 1):\n",
        "                wumpus_vivo = 0\n",
        "    elif action == 6:  # escalar\n",
        "        if x == 0 and y == 0:\n",
        "            if tem_ouro:\n",
        "                reward = RECOMPENSAS['escalar_com_ouro']\n",
        "                done = True\n",
        "            else:\n",
        "                reward = 0\n",
        "                done = True\n",
        "\n",
        "    # Verifica se caiu em abismo\n",
        "    if caverna[x][y] == 'A':\n",
        "        reward = RECOMPENSAS['abismo']\n",
        "        done = True\n",
        "    # Verifica se encontrou Wumpus\n",
        "    if caverna[x][y] == 'W' and wumpus_vivo:\n",
        "        reward = RECOMPENSAS['wumpus']\n",
        "        done = True\n",
        "    # Se pegou ouro, não termina o jogo, só se escalar\n",
        "    return (x, y, tem_flecha, tem_ouro, wumpus_vivo), reward, done\n",
        "\n",
        "# Q-learning simples\n",
        "def train_qlearning(episodios=500):\n",
        "    Q = {}\n",
        "    alpha = 0.1\n",
        "    gamma = 0.9\n",
        "    epsilon = 0.2\n",
        "    for ep in range(episodios):\n",
        "        state = reset_env()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        for t in range(100):\n",
        "            s_key = tuple(state)\n",
        "            if s_key not in Q:\n",
        "                Q[s_key] = np.zeros(len(ACTIONS))\n",
        "            # Política epsilon-greedy\n",
        "            if random.random() < epsilon:\n",
        "                action = random.randint(0, len(ACTIONS)-1)\n",
        "            else:\n",
        "                action = np.argmax(Q[s_key])\n",
        "            next_state, reward, done = step(state, action)\n",
        "            ns_key = tuple(next_state)\n",
        "            if ns_key not in Q:\n",
        "                Q[ns_key] = np.zeros(len(ACTIONS))\n",
        "            Q[s_key][action] += alpha * (reward + gamma * np.max(Q[ns_key]) - Q[s_key][action])\n",
        "            state = next_state\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        if (ep+1) % 50 == 0:\n",
        "            print(f\"Episódio {ep+1}: recompensa total = {total_reward}\")\n",
        "    return Q\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    Q = train_qlearning(300)\n",
        "    print(\"\\nTreinamento finalizado!\")\n",
        "    # Teste: executar uma trajetória greedy\n",
        "    state = reset_env()\n",
        "    done = False\n",
        "    print(\"\\nTrajetória greedy:\")\n",
        "    for _ in range(30):\n",
        "        print(f\"Posição: ({state[0]+1},{state[1]+1}), Ouro: {state[3]}, Wumpus vivo: {state[4]}\")\n",
        "        s_key = tuple(state)\n",
        "        if s_key in Q:\n",
        "            action = np.argmax(Q[s_key])\n",
        "        else:\n",
        "            action = random.randint(0, len(ACTIONS)-1)\n",
        "        state, reward, done = step(state, action)\n",
        "        if done:\n",
        "            print(\"Fim do episódio.\")\n",
        "            break"
      ]
    }
  ]
}